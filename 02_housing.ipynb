{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Lab 2 Tasks\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcinsawinski/UEP_KIE_ML_LAB_PROG/blob/main/02_housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note!\n",
    "Check hints in [Cheatsheet](https://colab.research.google.com/github/marcinsawinski/UEP_KIE_ML_LAB_PROG/blob/main/00_cheatsheet.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.1\n",
    "_Get data from url_housing and visualize_\n",
    "- Preview data, get statistics (.head(), .inf(), .describe())\n",
    "- Print data histogram\n",
    "\n",
    "\n",
    "_Type your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.2\n",
    "_Create train / test split (80/20)_\n",
    "- Create random split\n",
    "- Create stratifed split on income class (5 strata)\n",
    "\n",
    "\n",
    "_Type your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.3\n",
    "_Visualize_\n",
    "- Create plot using geographical data (lang, lat). Add alpha. Add color for median_house_value. Add size for population. OPTIONAL Add basemap (e.g. plotly.express)\n",
    "- Create correlation matrix\n",
    "- Plot correlation for median_income and median_house_value\n",
    "\n",
    "_Explore_\n",
    " - Make train dataframe  copy\n",
    " - Create 3 new features:\n",
    "    - rooms_per_household  = total_rooms / households, \n",
    "    - bedrooms_per_room = total_bedrooms / total_rooms\n",
    "    - population_per_household = population / households\n",
    "- Check correlation of new features\n",
    "\n",
    "_Type your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.4\n",
    "_Prepare_\n",
    "- Make train dataframe copy, drop label\n",
    "- Make train dataframe copy with label only\n",
    "\n",
    "_Clean_\n",
    " - Fill missing total_bedrooms with median value ( whe using inputer watch out for categorical features)\n",
    " - Convert categorical features into one-hot features\n",
    "\n",
    "\n",
    "_Type your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.5\n",
    "_Clean_\n",
    "- Remove outliers with Isolation forest\n",
    "- Standardize numerical variables\n",
    "- Try fixing distribution od population variable using:\n",
    "    - log function\n",
    "    - percentiles\n",
    "- Add rbf measure for value 35 of housing_median_age\n",
    "\n",
    "\n",
    "_Type your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.6\n",
    "_Generate custom transformations_\n",
    "- add log transformer for population\n",
    "- add rbf measure for value 35 of housing_median_age\n",
    "- add rooms_per_household, population_per_household, rooms_per_household (last one optional set by hyperparamter)\n",
    "\n",
    "_Generate custom pipeline to combine transformations__\n",
    "- pipeline for preprocessing the numerical attributes\n",
    "    - median inputer\n",
    "    - attributs adder\n",
    "    - StandardScaler\n",
    "- full pipeline witn numerical pipeline the numerical attributes and OneHotEncoder for categorical attributes\n",
    "\n",
    "_Type your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.7\n",
    "_Select and Train a Model_\n",
    "- Fit LinearRegression on data prepared with full pipline. Check SME, RSME and MAE\n",
    "- Fit DecisionTreeRegressor. Check RSME.\n",
    "- Fit RandomForestRegressor. Check RSME.\n",
    "- Fit SVR. Check RSME.\n",
    "- Peforem cross validation(cv=10). Compare results\n",
    "\n",
    "_Type your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.8\n",
    "_Tune Model_\n",
    "- Tune DecisionTreeRegressor with Grid Search with param grid:\n",
    "```python\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "```\n",
    "- Tune DecisionTreeRegressor with RandomizedSearchCV\n",
    "```python\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "```\n",
    "- Check scores\n",
    "- Check feature importances\n",
    "\n",
    "_Type your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.9\n",
    "_Evaluate Your System on the Test Set_\n",
    "- Predict result for test set with best_estimator. Check RSME.\n",
    "- Calcualte 95% confidence interval for the test RMSE\n",
    "\n",
    "_Type your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.10\n",
    "Extra tasks:\n",
    "- Write a full pipeline with both preparation and prediction (full_pipeline and LinearRegression)\n",
    "- Calculate 10 clusters and add RBF similarities features\n",
    "\n",
    "\n",
    "_Type your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.11\n",
    "_Try a Support Vector Machine regressor (`sklearn.svm.SVR`) with various hyperparameters, such as `kernel=\"linear\"` (with various values for the `C` hyperparameter) or `kernel=\"rbf\"` (with various values for the `C` and `gamma` hyperparameters). Note that SVMs don't scale well to large datasets, so you should probably train your model on just the first 5,000 instances of the training set and use only 3-fold cross-validation, or else it will take hours. How does the best `SVR` predictor perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.12\n",
    "_Try replacing the `GridSearchCV` with a `RandomizedSearchCV`._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.13\n",
    "_Try adding a `SelectFromModel` transformer in the preparation pipeline to select only the most important attributes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.14\n",
    "\n",
    "_Try creating a custom transformer that trains a k-Nearest Neighbors regressor (`sklearn.neighbors.KNeighborsRegressor`) in its `fit()` method, and outputs the model's predictions in its `transform()` method. Then add this feature to the preprocessing pipeline, using latitude and longitude as the inputs to this transformer. This will add a feature in the model that corresponds to the housing median price of the nearest districts._\n",
    "\n",
    "Rather than restrict ourselves to k-Nearest Neighbors regressors, let's create a transformer that accepts any regressor. For this, we can extend the `MetaEstimatorMixin` and have a required `estimator` argument in the constructor. The `fit()` method must work on a clone of this estimator, and it must also save `feature_names_in_`. The `MetaEstimatorMixin` will ensure that `estimator` is listed as a required parameters, and it will update `get_params()` and `set_params()` to make the estimator's hyperparameters available for tuning. Lastly, we create a `get_feature_names_out()` method: the output column name is the ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.15\n",
    "_Automatically explore some preparation options using `RandomSearchCV`._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.16\n",
    "_Try to implement the `StandardScalerClone` class again from scratch, then add support for the `inverse_transform()` method: executing `scaler.inverse_transform(scaler.fit_transform(X))` should return an array very close to `X`. Then add support for feature names: set `feature_names_in_` in the `fit()` method if the input is a DataFrame. This attribute should be a NumPy array of column names. Lastly, implement the `get_feature_names_out()` method: it should have one optional `input_features=None` argument. If passed, the method should check that its length matches `n_features_in_`, and it should match `feature_names_in_` if it is defined, then `input_features` should be returned. If `input_features` is `None`, then the method should return `feature_names_in_` if it is defined or `np.array([\"x0\", \"x1\", ...])` with length `n_features_in_` otherwise._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('hml3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) \n[Clang 13.0.1 ]"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ac2598a53cd48ed973662853cbed9ce85601c819c2e7e5e54efa32ca245c1cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
