{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 1 – The Machine Learning landscape**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcinsawinski/UEP_KIE_ML_LAB_PROG/raw/main/01_the_machine_learning_landscape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project requires Python 3.7 or above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn ≥1.0.1 is required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import sklearn\n",
    "\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the default font sizes, to plot pretty figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=12)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make this notebook's output stable across runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'https://github.com/marcinsawinski/UEP_KIE_ML_LAB_PROG/raw/main/datasets/'\n",
    "data_set_lifesat = 'lifesat/lifesat.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code example 1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m# Download and prepare the data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m data_root \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://github.com/marcinsawinski/UEP_KIE_ML_LAB_PROG/raw/main/datasets/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m lifesat \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(data_root \u001b[39m+\u001b[39;49m data_set_lifesat)\n\u001b[1;32m      9\u001b[0m X \u001b[39m=\u001b[39m lifesat[[\u001b[39m\"\u001b[39m\u001b[39mGDP per capita (USD)\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     10\u001b[0m y \u001b[39m=\u001b[39m lifesat[[\u001b[39m\"\u001b[39m\u001b[39mLife satisfaction\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1730\u001b[0m     f,\n\u001b[1;32m   1731\u001b[0m     mode,\n\u001b[1;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1738\u001b[0m )\n\u001b[1;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/site-packages/pandas/io/common.py:714\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    711\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    713\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    715\u001b[0m     path_or_buf,\n\u001b[1;32m    716\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    717\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    718\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    719\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    720\u001b[0m )\n\u001b[1;32m    722\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    723\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/site-packages/pandas/io/common.py:364\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    363\u001b[0m req_info \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[39m=\u001b[39mstorage_options)\n\u001b[0;32m--> 364\u001b[0m \u001b[39mwith\u001b[39;00m urlopen(req_info) \u001b[39mas\u001b[39;00m req:\n\u001b[1;32m    365\u001b[0m     content_encoding \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Encoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    366\u001b[0m     \u001b[39mif\u001b[39;00m content_encoding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    367\u001b[0m         \u001b[39m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/site-packages/pandas/io/common.py:266\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39mthe stdlib.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[1;32m    525\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[1;32m    633\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[1;32m    635\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/hml3/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Download and prepare the data\n",
    "data_root = 'https://github.com/marcinsawinski/UEP_KIE_ML_LAB_PROG/raw/main/datasets/'\n",
    "lifesat = pd.read_csv(data_root + data_set_lifesat)\n",
    "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
    "y = lifesat[[\"Life satisfaction\"]].values\n",
    "\n",
    "# Visualize the data\n",
    "lifesat.plot(kind='scatter', grid=True,\n",
    "             x=\"GDP per capita (USD)\", y=\"Life satisfaction\")\n",
    "plt.axis([23_500, 62_500, 4, 9])\n",
    "plt.show()\n",
    "\n",
    "# Select a linear model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make a prediction for Cyprus\n",
    "X_new = [[37_655.2]]  # Cyprus' GDP per capita in 2020\n",
    "print(model.predict(X_new)) # outputs [[6.30165767]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the Linear Regression model with k-Nearest Neighbors (in this example, k = 3) regression in the previous code is as simple as replacing these two\n",
    "lines:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "```\n",
    "\n",
    "with these two:\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a 3-Nearest Neighbors regression model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make a prediction for Cyprus\n",
    "print(model.predict(X_new)) # outputs [[6.33333333]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare Life satisfaction data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create `lifesat.csv`, I downloaded the Better Life Index (BLI) data from [OECD's website](http://stats.oecd.org/index.aspx?DataSetCode=BLI) (to get the Life Satisfaction for each country), and World Bank GDP per capita data from [OurWorldInData.org](https://ourworldindata.org/grapher/gdp-per-capita-worldbank). The BLI data is in `datasets/lifesat/oecd_bli.csv` (data from 2020), and the GDP per capita data is in `datasets/lifesat/gdp_per_capita.csv` (data up to 2020).\n",
    "\n",
    "If you want to grab the latest versions, please feel free to do so. However, there may be some changes (e.g., in the column names, or different countries missing data), so be prepared to have to tweak the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "datapath = Path() / \"datasets\" / \"lifesat\"\n",
    "datapath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
    "for filename in (\"oecd_bli.csv\", \"gdp_per_capita.csv\"):\n",
    "    if not (datapath / filename).is_file():\n",
    "        print(\"Downloading\", filename)\n",
    "        url = data_root + \"lifesat/\" + filename\n",
    "        urllib.request.urlretrieve(url, datapath / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli = pd.read_csv(datapath / \"oecd_bli.csv\")\n",
    "gdp_per_capita = pd.read_csv(datapath / \"gdp_per_capita.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the GDP per capita data to keep only the year 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_year = 2020\n",
    "gdppc_col = \"GDP per capita (USD)\"\n",
    "lifesat_col = \"Life satisfaction\"\n",
    "\n",
    "gdp_per_capita = gdp_per_capita[gdp_per_capita[\"Year\"] == gdp_year]\n",
    "gdp_per_capita = gdp_per_capita.drop([\"Code\", \"Year\"], axis=1)\n",
    "gdp_per_capita.columns = [\"Country\", gdppc_col]\n",
    "gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "\n",
    "gdp_per_capita.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the OECD BLI data to keep only the `Life satisfaction` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
    "oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "\n",
    "oecd_bli.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's merge the life satisfaction data and the GDP per capita data, keeping only the GDP per capita and Life satisfaction columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
    "                              left_index=True, right_index=True)\n",
    "full_country_stats.sort_values(by=gdppc_col, inplace=True)\n",
    "full_country_stats = full_country_stats[[gdppc_col, lifesat_col]]\n",
    "\n",
    "full_country_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the risk of overfitting, I use only part of the data in most figures (all countries with a GDP per capita between `min_gdp` and `max_gdp`). Later in the chapter I reveal the missing countries, and show that they don't follow the same linear trend at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_gdp = 23_500\n",
    "max_gdp = 62_500\n",
    "\n",
    "country_stats = full_country_stats[(full_country_stats[gdppc_col] >= min_gdp) &\n",
    "                                   (full_country_stats[gdppc_col] <= max_gdp)]\n",
    "country_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_stats.to_csv(datapath / \"lifesat.csv\")\n",
    "full_country_stats.to_csv(datapath / \"lifesat_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n",
    "                   x=gdppc_col, y=lifesat_col)\n",
    "\n",
    "min_life_sat = 4\n",
    "max_life_sat = 9\n",
    "\n",
    "position_text = {\n",
    "    \"Turkey\": (29_500, 4.2),\n",
    "    \"Hungary\": (28_000, 6.9),\n",
    "    \"France\": (40_000, 5),\n",
    "    \"New Zealand\": (28_000, 8.2),\n",
    "    \"Australia\": (50_000, 5.5),\n",
    "    \"United States\": (59_000, 5.3),\n",
    "    \"Denmark\": (46_000, 8.5)\n",
    "}\n",
    "\n",
    "for country, pos_text in position_text.items():\n",
    "    pos_data_x = country_stats[gdppc_col].loc[country]\n",
    "    pos_data_y = country_stats[lifesat_col].loc[country]\n",
    "    country = \"U.S.\" if country == \"United States\" else country\n",
    "    plt.annotate(country, xy=(pos_data_x, pos_data_y),\n",
    "                 xytext=pos_text, fontsize=12,\n",
    "                 arrowprops=dict(facecolor='black', width=0.5,\n",
    "                                 shrink=0.08, headwidth=5))\n",
    "    plt.plot(pos_data_x, pos_data_y, \"ro\")\n",
    "\n",
    "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
    "\n",
    "save_fig('money_happy_scatterplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlighted_countries = country_stats.loc[list(position_text.keys())]\n",
    "highlighted_countries[[gdppc_col, lifesat_col]].sort_values(by=gdppc_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n",
    "                   x=gdppc_col, y=lifesat_col)\n",
    "\n",
    "X = np.linspace(min_gdp, max_gdp, 1000)\n",
    "\n",
    "w1, w2 = 4.2, 0\n",
    "plt.plot(X, w1 + w2 * 1e-5 * X, \"r\")\n",
    "plt.text(40_000, 4.9, fr\"$\\theta_0 = {w1}$\", color=\"r\")\n",
    "plt.text(40_000, 4.4, fr\"$\\theta_1 = {w2}$\", color=\"r\")\n",
    "\n",
    "w1, w2 = 10, -9\n",
    "plt.plot(X, w1 + w2 * 1e-5 * X, \"g\")\n",
    "plt.text(26_000, 8.5, fr\"$\\theta_0 = {w1}$\", color=\"g\")\n",
    "plt.text(26_000, 8.0, fr\"$\\theta_1 = {w2} \\times 10^{{-5}}$\", color=\"g\")\n",
    "\n",
    "w1, w2 = 3, 8\n",
    "plt.plot(X, w1 + w2 * 1e-5 * X, \"b\")\n",
    "plt.text(48_000, 8.5, fr\"$\\theta_0 = {w1}$\", color=\"b\")\n",
    "plt.text(48_000, 8.0, fr\"$\\theta_1 = {w2} \\times 10^{{-5}}$\", color=\"b\")\n",
    "\n",
    "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
    "\n",
    "save_fig('tweaking_model_params_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "X_sample = country_stats[[gdppc_col]].values\n",
    "y_sample = country_stats[[lifesat_col]].values\n",
    "\n",
    "lin1 = linear_model.LinearRegression()\n",
    "lin1.fit(X_sample, y_sample)\n",
    "\n",
    "t0, t1 = lin1.intercept_[0], lin1.coef_[0][0]\n",
    "print(f\"θ0={t0:.2f}, θ1={t1:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n",
    "                   x=gdppc_col, y=lifesat_col)\n",
    "\n",
    "X = np.linspace(min_gdp, max_gdp, 1000)\n",
    "plt.plot(X, t0 + t1 * X, \"b\")\n",
    "\n",
    "plt.text(max_gdp - 20_000, min_life_sat + 1.9,\n",
    "         fr\"$\\theta_0 = {t0:.2f}$\", color=\"b\")\n",
    "plt.text(max_gdp - 20_000, min_life_sat + 1.3,\n",
    "         fr\"$\\theta_1 = {t1 * 1e5:.2f} \\times 10^{{-5}}$\", color=\"b\")\n",
    "\n",
    "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
    "\n",
    "save_fig('best_fit_model_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyprus_gdp_per_capita = gdp_per_capita[gdppc_col].loc[\"Cyprus\"]\n",
    "cyprus_gdp_per_capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyprus_predicted_life_satisfaction = lin1.predict([[cyprus_gdp_per_capita]])[0, 0]\n",
    "cyprus_predicted_life_satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n",
    "                   x=gdppc_col, y=lifesat_col)\n",
    "\n",
    "X = np.linspace(min_gdp, max_gdp, 1000)\n",
    "plt.plot(X, t0 + t1 * X, \"b\")\n",
    "\n",
    "plt.text(min_gdp + 22_000, max_life_sat - 1.1,\n",
    "         fr\"$\\theta_0 = {t0:.2f}$\", color=\"b\")\n",
    "plt.text(min_gdp + 22_000, max_life_sat - 0.6,\n",
    "         fr\"$\\theta_1 = {t1 * 1e5:.2f} \\times 10^{{-5}}$\", color=\"b\")\n",
    "\n",
    "plt.plot([cyprus_gdp_per_capita, cyprus_gdp_per_capita],\n",
    "         [min_life_sat, cyprus_predicted_life_satisfaction], \"r--\")\n",
    "plt.text(cyprus_gdp_per_capita + 1000, 5.0,\n",
    "         fr\"Prediction = {cyprus_predicted_life_satisfaction:.2f}\", color=\"r\")\n",
    "plt.plot(cyprus_gdp_per_capita, cyprus_predicted_life_satisfaction, \"ro\")\n",
    "\n",
    "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = full_country_stats[(full_country_stats[gdppc_col] < min_gdp) |\n",
    "                                  (full_country_stats[gdppc_col] > max_gdp)]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_text_missing_countries = {\n",
    "    \"South Africa\": (20_000, 4.2),\n",
    "    \"Colombia\": (6_000, 8.2),\n",
    "    \"Brazil\": (18_000, 7.8),\n",
    "    \"Mexico\": (24_000, 7.4),\n",
    "    \"Chile\": (30_000, 7.0),\n",
    "    \"Norway\": (51_000, 6.2),\n",
    "    \"Switzerland\": (62_000, 5.7),\n",
    "    \"Ireland\": (81_000, 5.2),\n",
    "    \"Luxembourg\": (92_000, 4.7),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_country_stats.plot(kind='scatter', figsize=(8, 3),\n",
    "                        x=gdppc_col, y=lifesat_col, grid=True)\n",
    "\n",
    "for country, pos_text in position_text_missing_countries.items():\n",
    "    pos_data_x, pos_data_y = missing_data.loc[country]\n",
    "    plt.annotate(country, xy=(pos_data_x, pos_data_y),\n",
    "                 xytext=pos_text, fontsize=12,\n",
    "                 arrowprops=dict(facecolor='black', width=0.5,\n",
    "                                 shrink=0.08, headwidth=5))\n",
    "    plt.plot(pos_data_x, pos_data_y, \"rs\")\n",
    "\n",
    "X = np.linspace(0, 115_000, 1000)\n",
    "plt.plot(X, t0 + t1 * X, \"b:\")\n",
    "\n",
    "lin_reg_full = linear_model.LinearRegression()\n",
    "Xfull = np.c_[full_country_stats[gdppc_col]]\n",
    "yfull = np.c_[full_country_stats[lifesat_col]]\n",
    "lin_reg_full.fit(Xfull, yfull)\n",
    "\n",
    "t0full, t1full = lin_reg_full.intercept_[0], lin_reg_full.coef_[0][0]\n",
    "X = np.linspace(0, 115_000, 1000)\n",
    "plt.plot(X, t0full + t1full * X, \"k\")\n",
    "\n",
    "plt.axis([0, 115_000, min_life_sat, max_life_sat])\n",
    "\n",
    "save_fig('representative_training_data_scatterplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "\n",
    "full_country_stats.plot(kind='scatter', figsize=(8, 3),\n",
    "                        x=gdppc_col, y=lifesat_col, grid=True)\n",
    "\n",
    "poly = preprocessing.PolynomialFeatures(degree=10, include_bias=False)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "lin_reg2 = linear_model.LinearRegression()\n",
    "\n",
    "pipeline_reg = pipeline.Pipeline([\n",
    "    ('poly', poly),\n",
    "    ('scal', scaler),\n",
    "    ('lin', lin_reg2)])\n",
    "pipeline_reg.fit(Xfull, yfull)\n",
    "curve = pipeline_reg.predict(X[:, np.newaxis])\n",
    "plt.plot(X, curve)\n",
    "\n",
    "plt.axis([0, 115_000, min_life_sat, max_life_sat])\n",
    "\n",
    "save_fig('overfitting_model_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_countries = [c for c in full_country_stats.index if \"W\" in c.upper()]\n",
    "full_country_stats.loc[w_countries][lifesat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_w_countries = [c for c in gdp_per_capita.index if \"W\" in c.upper()]\n",
    "gdp_per_capita.loc[all_w_countries].sort_values(by=gdppc_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_stats.plot(kind='scatter', x=gdppc_col, y=lifesat_col, figsize=(8, 3))\n",
    "missing_data.plot(kind='scatter', x=gdppc_col, y=lifesat_col,\n",
    "                  marker=\"s\", color=\"r\", grid=True, ax=plt.gca())\n",
    "\n",
    "X = np.linspace(0, 115_000, 1000)\n",
    "plt.plot(X, t0 + t1*X, \"b:\", label=\"Linear model on partial data\")\n",
    "plt.plot(X, t0full + t1full * X, \"k-\", label=\"Linear model on all data\")\n",
    "\n",
    "ridge = linear_model.Ridge(alpha=10**9.5)\n",
    "X_sample = country_stats[[gdppc_col]]\n",
    "y_sample = country_stats[[lifesat_col]]\n",
    "ridge.fit(X_sample, y_sample)\n",
    "t0ridge, t1ridge = ridge.intercept_[0], ridge.coef_[0][0]\n",
    "plt.plot(X, t0ridge + t1ridge * X, \"b--\",\n",
    "         label=\"Regularized linear model on partial data\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.axis([0, 115_000, min_life_sat, max_life_sat])\n",
    "\n",
    "save_fig('ridge_model_plot')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('hml3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "22b0ec00cd9e253c751e6d2619fc0bb2d18ed12980de3246690d5be49479dd65"
   }
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "616px",
   "left": "0px",
   "right": "20px",
   "top": "106px",
   "width": "213px"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac2598a53cd48ed973662853cbed9ce85601c819c2e7e5e54efa32ca245c1cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
